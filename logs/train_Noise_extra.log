2024-06-25 11:43:57,012 ==================================================
2024-06-25 11:43:57,013 Training with Guassian Noise of 8 length...
2024-06-25 11:43:58,946 Epoch [1/8], Batch [1/748], Loss: 1.5956
2024-06-25 11:44:48,076 Epoch [1/8], Batch [51/748], Loss: 1.5270
2024-06-25 11:45:38,333 Epoch [1/8], Batch [101/748], Loss: 1.3241
2024-06-25 11:46:28,610 Epoch [1/8], Batch [151/748], Loss: 1.2134
2024-06-25 11:47:19,116 Epoch [1/8], Batch [201/748], Loss: 1.1500
2024-06-25 11:48:09,732 Epoch [1/8], Batch [251/748], Loss: 1.2300
2024-06-25 11:49:00,184 Epoch [1/8], Batch [301/748], Loss: 0.9773
2024-06-25 11:49:50,928 Epoch [1/8], Batch [351/748], Loss: 0.9326
2024-06-25 11:50:41,620 Epoch [1/8], Batch [401/748], Loss: 1.0653
2024-06-25 11:51:31,952 Epoch [1/8], Batch [451/748], Loss: 1.1385
2024-06-25 11:52:22,445 Epoch [1/8], Batch [501/748], Loss: 0.9823
2024-06-25 11:53:13,056 Epoch [1/8], Batch [551/748], Loss: 1.0451
2024-06-25 11:54:03,464 Epoch [1/8], Batch [601/748], Loss: 0.7224
2024-06-25 11:54:54,401 Epoch [1/8], Batch [651/748], Loss: 0.8202
2024-06-25 11:55:45,073 Epoch [1/8], Batch [701/748], Loss: 0.8751
2024-06-25 11:56:32,031 Epoch 1/8, Train Loss: 1.0588, Train Accuracy: 0.5456
2024-06-25 11:57:56,150 Epoch 1/8, Val Loss: 0.8660, Val Accuracy: 0.6293
2024-06-25 11:57:57,198 Epoch [2/8], Batch [1/748], Loss: 0.7113
2024-06-25 11:58:47,680 Epoch [2/8], Batch [51/748], Loss: 0.9317
2024-06-25 11:59:38,082 Epoch [2/8], Batch [101/748], Loss: 1.0185
2024-06-25 12:00:28,654 Epoch [2/8], Batch [151/748], Loss: 0.7986
2024-06-25 12:01:19,515 Epoch [2/8], Batch [201/748], Loss: 0.7175
2024-06-25 12:02:10,548 Epoch [2/8], Batch [251/748], Loss: 0.7944
2024-06-25 12:03:01,418 Epoch [2/8], Batch [301/748], Loss: 0.6791
2024-06-25 12:03:51,870 Epoch [2/8], Batch [351/748], Loss: 0.8711
2024-06-25 12:04:42,360 Epoch [2/8], Batch [401/748], Loss: 0.8855
2024-06-25 12:05:33,224 Epoch [2/8], Batch [451/748], Loss: 0.8021
2024-06-25 12:06:24,037 Epoch [2/8], Batch [501/748], Loss: 0.8138
2024-06-25 12:07:14,785 Epoch [2/8], Batch [551/748], Loss: 0.7152
2024-06-25 12:08:05,208 Epoch [2/8], Batch [601/748], Loss: 0.8897
2024-06-25 12:08:56,058 Epoch [2/8], Batch [651/748], Loss: 0.8585
2024-06-25 12:09:46,651 Epoch [2/8], Batch [701/748], Loss: 0.8425
2024-06-25 12:10:33,799 Epoch 2/8, Train Loss: 0.7992, Train Accuracy: 0.6528
2024-06-25 12:11:58,250 Epoch 2/8, Val Loss: 0.7823, Val Accuracy: 0.6639
2024-06-25 12:11:59,245 Epoch [3/8], Batch [1/748], Loss: 0.6535
2024-06-25 12:12:49,930 Epoch [3/8], Batch [51/748], Loss: 0.7749
2024-06-25 12:13:40,331 Epoch [3/8], Batch [101/748], Loss: 0.6215
2024-06-25 12:14:31,314 Epoch [3/8], Batch [151/748], Loss: 0.5753
2024-06-25 12:15:21,820 Epoch [3/8], Batch [201/748], Loss: 0.7813
2024-06-25 12:16:12,243 Epoch [3/8], Batch [251/748], Loss: 0.7020
2024-06-25 12:17:03,037 Epoch [3/8], Batch [301/748], Loss: 0.7729
2024-06-25 12:17:53,982 Epoch [3/8], Batch [351/748], Loss: 0.6978
2024-06-25 12:18:44,965 Epoch [3/8], Batch [401/748], Loss: 0.7598
2024-06-25 12:19:35,904 Epoch [3/8], Batch [451/748], Loss: 0.6494
2024-06-25 12:20:26,820 Epoch [3/8], Batch [501/748], Loss: 0.7652
2024-06-25 12:21:17,776 Epoch [3/8], Batch [551/748], Loss: 0.5144
2024-06-25 12:22:08,194 Epoch [3/8], Batch [601/748], Loss: 0.4703
2024-06-25 12:22:59,051 Epoch [3/8], Batch [651/748], Loss: 0.4889
2024-06-25 12:23:49,706 Epoch [3/8], Batch [701/748], Loss: 0.8240
2024-06-25 12:24:36,897 Epoch 3/8, Train Loss: 0.6825, Train Accuracy: 0.7112
2024-06-25 12:26:01,584 Epoch 3/8, Val Loss: 0.8274, Val Accuracy: 0.6527
2024-06-25 12:26:02,619 Epoch [4/8], Batch [1/748], Loss: 0.5590
2024-06-25 12:26:53,222 Epoch [4/8], Batch [51/748], Loss: 0.5831
2024-06-25 12:27:43,896 Epoch [4/8], Batch [101/748], Loss: 0.5028
2024-06-25 12:28:34,586 Epoch [4/8], Batch [151/748], Loss: 0.6253
2024-06-25 12:29:25,069 Epoch [4/8], Batch [201/748], Loss: 0.3981
2024-06-25 12:30:15,699 Epoch [4/8], Batch [251/748], Loss: 0.5816
2024-06-25 12:31:06,446 Epoch [4/8], Batch [301/748], Loss: 0.4273
2024-06-25 12:31:56,723 Epoch [4/8], Batch [351/748], Loss: 0.4396
2024-06-25 12:32:47,459 Epoch [4/8], Batch [401/748], Loss: 0.4246
2024-06-25 12:33:38,204 Epoch [4/8], Batch [451/748], Loss: 0.4217
2024-06-25 12:34:28,738 Epoch [4/8], Batch [501/748], Loss: 0.4764
2024-06-25 12:35:19,324 Epoch [4/8], Batch [551/748], Loss: 0.3853
2024-06-25 12:36:10,257 Epoch [4/8], Batch [601/748], Loss: 0.5131
2024-06-25 12:37:01,089 Epoch [4/8], Batch [651/748], Loss: 0.7210
2024-06-25 12:37:51,933 Epoch [4/8], Batch [701/748], Loss: 0.5028
2024-06-25 12:38:39,219 Epoch 4/8, Train Loss: 0.5664, Train Accuracy: 0.7670
2024-06-25 12:40:03,880 Epoch 4/8, Val Loss: 0.7564, Val Accuracy: 0.6935
2024-06-25 12:40:04,871 Epoch [5/8], Batch [1/748], Loss: 0.6693
2024-06-25 12:40:55,393 Epoch [5/8], Batch [51/748], Loss: 0.3271
2024-06-25 12:41:46,109 Epoch [5/8], Batch [101/748], Loss: 0.3169
2024-06-25 12:42:36,872 Epoch [5/8], Batch [151/748], Loss: 0.4518
2024-06-25 12:43:27,547 Epoch [5/8], Batch [201/748], Loss: 0.5301
2024-06-25 12:44:18,140 Epoch [5/8], Batch [251/748], Loss: 0.5641
2024-06-25 12:45:08,975 Epoch [5/8], Batch [301/748], Loss: 0.2670
2024-06-25 12:45:59,608 Epoch [5/8], Batch [351/748], Loss: 0.3133
2024-06-25 12:46:50,335 Epoch [5/8], Batch [401/748], Loss: 0.4871
2024-06-25 12:47:40,922 Epoch [5/8], Batch [451/748], Loss: 0.4246
2024-06-25 12:48:31,968 Epoch [5/8], Batch [501/748], Loss: 0.4579
2024-06-25 12:49:22,637 Epoch [5/8], Batch [551/748], Loss: 0.3882
2024-06-25 12:50:13,059 Epoch [5/8], Batch [601/748], Loss: 0.5174
2024-06-25 12:51:03,538 Epoch [5/8], Batch [651/748], Loss: 0.5175
2024-06-25 12:51:54,377 Epoch [5/8], Batch [701/748], Loss: 0.4605
2024-06-25 12:52:41,957 Epoch 5/8, Train Loss: 0.4625, Train Accuracy: 0.8157
2024-06-25 12:54:06,598 Epoch 5/8, Val Loss: 0.8335, Val Accuracy: 0.6870
2024-06-25 12:54:07,598 Epoch [6/8], Batch [1/748], Loss: 0.5987
2024-06-25 12:54:58,255 Epoch [6/8], Batch [51/748], Loss: 0.2933
2024-06-25 12:55:48,783 Epoch [6/8], Batch [101/748], Loss: 0.2560
2024-06-25 12:56:39,709 Epoch [6/8], Batch [151/748], Loss: 0.4485
2024-06-25 12:57:30,608 Epoch [6/8], Batch [201/748], Loss: 0.4098
2024-06-25 12:58:21,557 Epoch [6/8], Batch [251/748], Loss: 0.1231
2024-06-25 12:59:12,407 Epoch [6/8], Batch [301/748], Loss: 0.3047
2024-06-25 13:00:02,764 Epoch [6/8], Batch [351/748], Loss: 0.2204
2024-06-25 13:00:53,580 Epoch [6/8], Batch [401/748], Loss: 0.4987
2024-06-25 13:01:44,314 Epoch [6/8], Batch [451/748], Loss: 0.4865
2024-06-25 13:02:35,239 Epoch [6/8], Batch [501/748], Loss: 0.2997
2024-06-25 13:03:26,077 Epoch [6/8], Batch [551/748], Loss: 0.4863
2024-06-25 13:04:16,602 Epoch [6/8], Batch [601/748], Loss: 0.3992
2024-06-25 13:05:07,144 Epoch [6/8], Batch [651/748], Loss: 0.2217
2024-06-25 13:05:57,776 Epoch [6/8], Batch [701/748], Loss: 0.8675
2024-06-25 13:06:44,623 Epoch 6/8, Train Loss: 0.3580, Train Accuracy: 0.8631
2024-06-25 13:08:09,111 Epoch 6/8, Val Loss: 1.0992, Val Accuracy: 0.6380
2024-06-25 13:08:10,124 Epoch [7/8], Batch [1/748], Loss: 0.2372
2024-06-25 13:09:00,408 Epoch [7/8], Batch [51/748], Loss: 0.1641
2024-06-25 13:09:51,288 Epoch [7/8], Batch [101/748], Loss: 0.2320
2024-06-25 13:10:42,217 Epoch [7/8], Batch [151/748], Loss: 0.2701
2024-06-25 13:11:33,198 Epoch [7/8], Batch [201/748], Loss: 0.1801
2024-06-25 13:12:24,000 Epoch [7/8], Batch [251/748], Loss: 0.1544
2024-06-25 13:13:14,823 Epoch [7/8], Batch [301/748], Loss: 0.8296
2024-06-25 13:14:05,045 Epoch [7/8], Batch [351/748], Loss: 0.2699
2024-06-25 13:14:55,647 Epoch [7/8], Batch [401/748], Loss: 0.3308
2024-06-25 13:15:46,182 Epoch [7/8], Batch [451/748], Loss: 0.3103
2024-06-25 13:16:36,837 Epoch [7/8], Batch [501/748], Loss: 0.4982
2024-06-25 13:17:27,570 Epoch [7/8], Batch [551/748], Loss: 0.1805
2024-06-25 13:18:17,859 Epoch [7/8], Batch [601/748], Loss: 0.3483
2024-06-25 13:19:08,701 Epoch [7/8], Batch [651/748], Loss: 0.1305
2024-06-25 13:19:59,481 Epoch [7/8], Batch [701/748], Loss: 0.1434
2024-06-25 13:20:46,931 Epoch 7/8, Train Loss: 0.2703, Train Accuracy: 0.9006
2024-06-25 13:22:11,122 Epoch 7/8, Val Loss: 1.0093, Val Accuracy: 0.6812
2024-06-25 13:22:12,140 Epoch [8/8], Batch [1/748], Loss: 0.1909
2024-06-25 13:23:02,599 Epoch [8/8], Batch [51/748], Loss: 0.1975
2024-06-25 13:23:52,847 Epoch [8/8], Batch [101/748], Loss: 0.2304
2024-06-25 13:24:43,741 Epoch [8/8], Batch [151/748], Loss: 0.0702
2024-06-25 13:25:34,319 Epoch [8/8], Batch [201/748], Loss: 0.4149
2024-06-25 13:26:24,603 Epoch [8/8], Batch [251/748], Loss: 0.1689
2024-06-25 13:27:15,414 Epoch [8/8], Batch [301/748], Loss: 0.1623
2024-06-25 13:28:05,935 Epoch [8/8], Batch [351/748], Loss: 0.1148
2024-06-25 13:28:56,354 Epoch [8/8], Batch [401/748], Loss: 0.1547
2024-06-25 13:29:46,878 Epoch [8/8], Batch [451/748], Loss: 0.3600
2024-06-25 13:30:37,432 Epoch [8/8], Batch [501/748], Loss: 0.4965
2024-06-25 13:31:28,082 Epoch [8/8], Batch [551/748], Loss: 0.3707
2024-06-25 13:32:18,590 Epoch [8/8], Batch [601/748], Loss: 0.4011
2024-06-25 13:33:09,293 Epoch [8/8], Batch [651/748], Loss: 0.0995
2024-06-25 13:33:59,629 Epoch [8/8], Batch [701/748], Loss: 0.1748
2024-06-25 13:34:46,650 Epoch 8/8, Train Loss: 0.2069, Train Accuracy: 0.9255
2024-06-25 13:36:10,815 Epoch 8/8, Val Loss: 1.2686, Val Accuracy: 0.6414
2024-06-25 13:36:10,816 Training finished!
2024-06-25 13:36:10,817 ==================================================
